{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DTSC 580: Data Manipulation\n",
    "## Assignment: LEGO Project\n",
    "### Name: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![LegoSchema](Lego_Schema.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In this assignment, you will load the various tables from the [Rebrickable](https://rebrickable.com/) website and perform analysis on the data.  Rebrickable is a fantastic website that is used to show you which LEGO sets you can build from the sets and parts you already own.  They will even show you which parts you are missing to complete the new set and suggest sets that you could purchase to get those parts.  \n",
    "\n",
    "## Data\n",
    "\n",
    "The data has been downloaded directly from their website and includes files for the tables shown in the schema above.  Your first task will be to go through the data and review the schema to understand how the tables all fit together.  There is no data dictionary that I am aware of, but you should be able to understand this data by reviewing the files and schema and visiting their [Download](https://rebrickable.com/downloads/) page and [API](https://rebrickable.com/api/) documentation.  **Note that you must use the files downloaded from Brightspace for this assignment and not download new files from the Rebrickable website.**\n",
    "\n",
    "## Assignment\n",
    "\n",
    "In this assignment, you will create a number of functions to complete certain tasks.  This is not needed if you were working on this project on your own, but since we want to see if you can select the data via Pandas/Numpy, we will use those functions in the automatic grading in CodeGrade.  Without this, students could try to look up the answers in the `csv` files instead of wrangling the data with Python/Pandas, which would defeat the purpose of this class.\n",
    "\n",
    "In addition, we would strongly suggest that you merge data sets as appropriate for the given task.  For example, you might merge the `sets` and `themes` DataFrames to answer one question, and then merge `sets`, `inventories`, `inventory_minifigs`, and `minifigs` to answer another.  This will make your code much easier to write and will be key in working with data across multiple tables.  In fact, I was able to create each function with only one line of code because of the merging of certain data sets.  Also note that you may not use all the tables in this assignment.  This is also an important skill for a Data Scientist to know when to use data and what data is unnecessary.\n",
    "\n",
    "When complete, save your notebook as `lego.ipynb` and submit to CodeGrade for automatic grading.\n",
    "\n",
    "## Note\n",
    "\n",
    "<u>Show Work</u>\n",
    "\n",
    "Remember that you must show your work.  Students submissions are spot checked manually throughout the term to verify that they are not hard coding the answer from looking only in the file or in CodeGrade's expected output.  If this is seen, the student's answer will be manually marked wrong and their grade will be changed to reflect this. \n",
    "\n",
    "For example, if the answer to Q1, the mean of a specific column, is 22:\n",
    "```\n",
    "# correct way\n",
    "Q1 = df['column_name'].mean()\n",
    "\n",
    "# incorrect way\n",
    "Q1 = 22 \n",
    "```\n",
    "\n",
    "Let's start out by importing some standard imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Do not change this option; This allows the CodeGrade auto grading to function correctly\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data\n",
    "\n",
    "Load the various Lego datasets below calling them the same as the name of the table as seen in the schema.  Note that you may or may not have to use all the data sets.  One of the things that all Data Scientists and Analysts have to decide when working on a project is what data is useful for a task and what data is not.  Remember to look at the schema above to see how all the data sets are connected.\n",
    "\n",
    "The autograder in CodeGrade will have the `csv` files in the same location where the notebook is run.  Because of this, please make sure your local files are in the same location as your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Lego data sets here\n",
    "# make sure that files are in the same folder as your notebook\n",
    "inventories = pd.read_csv('inventories.csv')\n",
    "inventory_sets = pd.read_csv('inventory_sets.csv')\n",
    "sets = pd.read_csv('sets.csv')\n",
    "themes = pd.read_csv('themes.csv')\n",
    "inventory_minifigs = pd.read_csv('inventory_minifigs.csv')\n",
    "minifigs = pd.read_csv('minifigs.csv')\n",
    "inventory_parts = pd.read_csv('inventory_parts.csv')\n",
    "part_categories = pd.read_csv('part_categories.csv')\n",
    "parts = pd.read_csv('parts.csv')\n",
    "colors = pd.read_csv('colors.csv')\n",
    "part_relationships = pd.read_csv('part_relationships.csv')\n",
    "elements = pd.read_csv('elements.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take time to look at all of the data sets using `.head()`, `.info()`, `.describe()`, etc to familiarize yourself with the data sets.  As you look at them, notice how the various tables connect together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable Name: "
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "dictionary changed size during iteration",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m df \u001b[38;5;129;01min\u001b[39;00m dataframes:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVariable Name: \u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m():\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m()[name] \u001b[38;5;129;01mis\u001b[39;00m df:\n\u001b[0;32m      7\u001b[0m             \u001b[38;5;28mprint\u001b[39m(name)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: dictionary changed size during iteration"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment\n",
    "\n",
    "Answer all the questions below using the available data.  There are multiple ways to get some of the answers.  I would suggest that you attempt to merge some data sets as needed to assist with getting answers.  This will make your tasks a lot easier and your code will be cleaner.\n",
    "\n",
    "Also, you will be creating functions to get the answers to some of these questions.  This will make it much easier for you to get answers to similar questions in the future and CodeGrade will be checking your functions using different inputs.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1:** Create a function called `data_count` that takes as input the data set (for example: `sets`) and returns the total number of rows in the data (as an integer).  Nothing else should be returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_count(data):\n",
    "    return int(data.shape[0])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code Check:**  If you call your `data_count` function using the `sets` DataFrame, you should see that there are 18,576 sets represented in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_count(sets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2:** What is the average number of parts for a Lego set (rounded to the nearest integer)?  Save this as `Q2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2 = round(sets['num_parts'].mean())\n",
    "Q2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3:** What is the median number of parts per set (output as an integer)?  Save this as `Q3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3 = round(sets['num_parts'].median())\n",
    "Q3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see that the median number of parts is much lower than the average number of parts per set.  This tells us that there are some Lego sets with a very high number of parts that brings the average up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4:** What is the largest number of parts that a set has? Save this as `Q4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4 = sets['num_parts'].max()\n",
    "Q4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5:** Given the set with the largest number of parts calculated above, select its row from the `sets` DataFrame.  Save this as `Q5`.  Do not reset the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5 = sets.loc[sets['num_parts'].idxmax()].to_frame().T\n",
    "Q5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q6:** Create a function called `select_set_row` where you pass it the `set_num` (as a string) and the function returns the respective row of the DataFrame from `sets`. Do not reset the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_set_row(set_num):\n",
    "    return sets.loc[sets['set_num'] == set_num]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q7:** Create a function called `select_set_numparts` that takes as input a specific number of parts (as an integer) and selects all the rows in the `sets` DataFrame that contain those number of parts.  Return the DataFrame sorted by `year` and then by `set_num`.  Do not reset the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_set_numparts(numparts):\n",
    "    sets_filtered = sets[sets[\"num_parts\"] == numparts]\n",
    "    sets_filtered = sets_filtered.sort_values(by=[\"year\", \"set_num\"])\n",
    "    return sets_filtered\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code Check:** Call the `select_set_numparts()` function to select all sets with `0` number of parts.  There should be 3,146 rows returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_set_numparts(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q8:** \n",
    "- The oldest set listed was made in what year?  Save the year as `Q8A` (as an integer).  \n",
    "- The newest set listed was made in what year? Save the year as `Q8B` (as an integer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q8A = sets['year'].min()\n",
    "Q8A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q8B = sets['year'].max()\n",
    "Q8B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q9:** \n",
    "- Create a function called `select_set_year` that takes as input a year (as an integer) and returns the rows from the `sets` DataFrame that matches that year.  Sort the DataFrame by `set_num`.  Do not reset the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_set_year(year):\n",
    "    return sets[sets['year'] == int(year)].sort_values('set_num')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q10:** \n",
    "- Create a function called `theme_by_year` that takes as input a year (as an integer) and shows the theme ids and theme names (listed in order by theme id) that were in sets that year.  \n",
    "- The column names must be `id` and `name_themes` (to differentiate between the name of a theme and the name of a set) in that order.  \n",
    "- The index should be reset and go from `0` to `n-1`.  \n",
    "- Each theme should only be listed once even if it appeared in more than one set from that year -- duplicate themes should be based on theme id and not name since there are some themes with the same name but with a different id.\n",
    "- Hint:  It will help if you were to think about merging appropriate DataFrames to help you get this answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def theme_by_year(year):\n",
    "    sets_year = sets[sets['year'] == year][['set_num', 'theme_id']]\n",
    "    themes_year = pd.merge(sets_year, themes, left_on='theme_id', right_on='id', how='inner')[['id', 'name']].drop_duplicates(subset='id').sort_values(by='id')\n",
    "    themes_year.columns = ['id', 'name_themes']\n",
    "    themes_year.reset_index(drop=True, inplace=True)\n",
    "    return themes_year\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code Check:** Call the `theme_by_year()` function on the year `1960`.  Your output should look as follows:\n",
    "\n",
    "| | id | name_themes|\n",
    "|-|---|---|\n",
    "|0|371|Supplemental|\n",
    "|1|497|Books|\n",
    "|2|513|Classic|\n",
    "\n",
    "**Optional Practice:** Call the `theme_by_year()` function using your birth year to see the Lego themes that were popular when you were born."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theme_by_year(1960)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q11:** \n",
    "- Create a function called `theme_by_name` that takes as input a theme name and outputs all the sets (in `set_num` order) that had that theme.  \n",
    "- The DataFrame should include the following columns in this order and with these exact names: `set_num`,`name_sets`,`year`,`num_parts`, `theme_id`, and `name_themes`.  \n",
    "- The index should go from `0` to `n-1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def theme_by_name(theme_name):\n",
    "    sets_theme = pd.merge(sets, themes, how='inner', left_on='theme_id', right_on='id')\n",
    "    sets_theme = sets_theme[sets_theme['name_y'] == theme_name]\n",
    "    sets_theme = sets_theme[['set_num', 'name_x', 'year', 'num_parts', 'theme_id', 'name_y']]\n",
    "    sets_theme = sets_theme.rename(columns={'name_x': 'name_sets', 'name_y': 'name_themes'})\n",
    "    sets_theme = sets_theme[['set_num', 'name_sets', 'year', 'num_parts', 'theme_id', 'name_themes']]\n",
    "    return sets_theme.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code Check:** Call the `theme_by_name()` function using the theme name `Gear`.  You should return 1,904 sets that match that theme name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theme_by_name('Friends')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q12:** Create a function called `theme_by_setnum` that takes as input the set_num (as a string) and returns the respective theme name as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def theme_by_setnum(set_num):\n",
    "    set_row = sets.loc[sets['set_num'] == set_num]\n",
    "    theme_id = set_row['theme_id'].values[0]\n",
    "    theme_row = themes.loc[themes['id'] == theme_id]\n",
    "    return theme_row['name'].values[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code Check:** Visit the [Sets page](https://rebrickable.com/sets/) from the Rebrickable website and find a set that you like.  Call your `theme_by_setnum()` function on that set and make sure the correct theme name is output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theme_by_setnum('41165-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Millennium Falcon Prep Exercise:** Find all the sets named 'Millennium Falcon'. Of these sets, find the set with the largest number of parts.  You will use this information for later questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Filter the sets DataFrame by name\n",
    "falcon_sets = sets[sets['name'].str.contains('Millennium Falcon')]\n",
    "falcon_sets\n",
    "# Sort by number of parts and take the first row\n",
    "falcon_set = falcon_sets.sort_values('num_parts', ascending=False).head(1)\n",
    "falcon_set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q13:** \n",
    "- How many minifigs are contained in the set from the `Millennium Falcon Prep Exercise`?  Save this as `Q13` (as an integer).  \n",
    "- Note that there are sometimes multiple versions of a set as shown in the `inventories` table.  This will not matter for this question as there is only one version for the respective set but this should be noted for future questions.\n",
    "- Remember to show your work or your answer will manually get marked as incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "inventory_id = inventories[(inventories['set_num'] == '75192-1')]['id'].iloc[0]\n",
    "\n",
    "figs = inventory_minifigs[inventory_minifigs['inventory_id'] == inventory_id]\n",
    "\n",
    "Q13 = len(figs)\n",
    "Q13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q14:** \n",
    "- Create a function called `get_minifigs` that takes as input a set number (as a string) and a version number (as an integer) and outputs all minifigs from that set / version combination.  \n",
    "- The DataFrame should be in `fig_num` order with the following columns/column names: `set_num`, `fig_num`, `fig_name`, `fig_num_parts`.  \n",
    "- The index should go from 0 to n-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_minifigs(set_num, version):\n",
    "    # merge inventories and inventory_minifigs\n",
    "    inv_minifigs = pd.merge(inventories, inventory_minifigs, left_on='id', right_on='inventory_id')\n",
    "\n",
    "    # filter by set_num and version\n",
    "    inv_minifigs = inv_minifigs[(inv_minifigs['set_num'] == set_num) & (inv_minifigs['version'] == version)]\n",
    "\n",
    "    # merge with minifigs\n",
    "    result = pd.merge(inv_minifigs, minifigs, on='fig_num')\n",
    "\n",
    "    # select the desired columns and rename them\n",
    "    result = result[['set_num', 'fig_num', 'name', 'num_parts']]\n",
    "    result = result.rename(columns={'name': 'fig_name', 'num_parts': 'fig_num_parts'})\n",
    "\n",
    "    # sort by fig_num and reset the index\n",
    "    result = result.sort_values('fig_num').reset_index(drop=True)\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q15:** Using the above function, output information about the minifigs from the set discussed in the `Millennium Falcon Prep Exercise`.  Save this output as `Q15`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q15 = get_minifigs('10246-1', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code Check:** Make sure that your `get_minifigs()` function works with both version 1 and version 2 of set 10217-1, Harry Potter's Diagon Alley.  Both versions should have 11 minifigs in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_minifigs('10217-1', 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q16:** \n",
    "- Create a function called `minifigs_from_themes` that takes as input a theme id (as an integer) and outputs all the minifigs contained in sets with that theme.  \n",
    "- The DataFrame should be in `fig_num` order with the following columns/column names: `fig_num`, `fig_name`. \n",
    "- The index should go from 0 to n-1.  \n",
    "- Exact duplicates should be removed so that only unique figs are included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minifigs_from_themes(theme_id):\n",
    "    sets_theme = sets[sets['theme_id'] == theme_id]\n",
    "    new_mini = pd.merge(minifigs, inventory_minifigs, on='fig_num')\n",
    "    new_mini = pd.merge(new_mini, inventories, left_on='inventory_id', right_on='id')\n",
    "    mini_themes = pd.merge(new_mini, sets_theme, on='set_num')\n",
    "    mini_themes = mini_themes.rename(columns={'name_x': 'fig_name'})\n",
    "    mini_themes = mini_themes[['fig_num', 'fig_name']].sort_values('fig_num')\n",
    "    mini_themes = mini_themes.drop_duplicates()\n",
    "    return mini_themes.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code Check:** Call the `minifigs_from_themes()` function using the theme number of the set discussed in the `Millennium Falcon Prep Exercise`.  There should be 149 minifigs output for that respective theme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minifigs_from_themes(171)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q17:** \n",
    "- Create a function called `sets_from_minifig` that takes as input a minifig number (as a string) and returns a list of sets a minifig has appeared in.  \n",
    "- Return a DataFrame (sorted by `set_num` and then by `version`) with the following columns: `set_num`, `version`,`name_sets`, `fig_num`, `fig_name`.  \n",
    "- The index should go from 0 to n-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sets_from_minifig(minifig_num):\n",
    "    sets_with_minifig = inventory_minifigs[inventory_minifigs['fig_num'] == minifig_num]\n",
    "    invmini_inv = pd.merge(sets_with_minifig, inventories, left_on='inventory_id', right_on='id')\n",
    "    mini_sets = pd.merge(invmini_inv, sets, on='set_num').sort_values(['set_num', 'version'])\n",
    "    mini_sets = pd.merge(mini_sets, minifigs, on='fig_num', suffixes=('_sets', '_fig'))\n",
    "    mini_sets = mini_sets.rename(columns={'name_fig': 'fig_name'})\n",
    "    mini_sets = mini_sets.loc[:, ['set_num', 'version', 'name_sets', 'fig_num', 'fig_name']].sort_values(['set_num','version'])\n",
    "    return mini_sets\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code Check:** Call your `sets_from_minifig()` function on one of the Lego Friends minifigs, Andrea, who has figure number: `fig-001039`.  Your function should return a DataFrame that contains the following sets:\n",
    "\n",
    "- Andrea on the Beach\n",
    "- Birthday Party\n",
    "- City Park Cafe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets_from_minifig('fig-001039')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q18:** \n",
    "\n",
    "*Note:  Before you begin working on this question, please note that CodeGrade has a 1GB RAM limit.  If you see an `Exit -9` code when submitting your assignment, it is probably due to this RAM limit and previous students had an issue with this question causing too much memory usage.  The biggest thing to think about is to only use the tables that you need to answer for this question.  For instance, you do not need any of the minifigs data since this is not needed for the output and the merging of this data could cause the number of rows to \"explode\" in terms of the total count.  I understand that this can be annoying that we have to work around CodeGrade's limitations, but it is good practice in memory management.*\n",
    "\n",
    "*You should only need to merge the following datasets for this answer so as to not go above the RAM limit: `themes`, `sets`, `inventories`, `inventory_parts`, `parts`, and `colors`*\n",
    "\n",
    "- Create a function called `set_parts` that takes as input the set number (as a string) and version number (as an integer) and outputs a DataFrame with each part in the set.  \n",
    "- The DataFrame should have the following columns/column names: `set_num`, `version`, `name_sets`, `year`, `name_themes`, `part_num`, `name_part`, `name_color`,`quantity`,`is_spare`.  \n",
    "- The Data should be sorted by `part_num` and then `name_color`.  \n",
    "- The index should go from 0 to n-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def set_parts(set_num, version):\n",
    "    set_inventory_id = inventories[(inventories['set_num'] == set_num) & (inventories['version'] == version)]\n",
    "    merged_themes_sets = themes.merge(sets, left_on='id', right_on='theme_id', suffixes=(\"_themes\", \"_sets\"))\n",
    "    themes_sets_inventories = pd.merge(merged_themes_sets, set_inventory_id, on='set_num', how='inner')\n",
    "    themes_sets_inventories = themes_sets_inventories.rename(columns={'id_x': 'set_id', 'id_y': 'inventory_id'})\n",
    "    themes_sets_inventories_parts = pd.merge(themes_sets_inventories, inventory_parts, on='inventory_id')\n",
    "    merged_df = pd.merge(themes_sets_inventories_parts, parts, on='part_num')\n",
    "    merged_df = pd.merge(merged_df, colors, left_on='part_cat_id', right_on='id', suffixes=('_part', '_colors'))\n",
    "    merged_df = merged_df.rename(columns={\n",
    "                        'name_colors': 'name_color'\n",
    "                        })\n",
    "    merged_df = merged_df[['set_num', 'version', 'name_sets', 'year', 'name_themes', 'part_num', 'name_part', \n",
    "                            'name_color', 'quantity', 'is_spare']].sort_values(['part_num', 'name_color']).reset_index()\n",
    "   \n",
    "    return merged_df\n",
    "\n",
    "\n",
    "set_parts('75192-1',1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code Check**: Using the `set_parts()` function, output a list of parts for the set discussed in the `Millennium Falcon Prep Exercise`. There should be a total of 730 rows in the DataFrame, which includes 676 parts and 54 spare parts. You can check the respective page on the rebrickable website to verify these results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_parts('21041-1',2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional Exercises\n",
    "These exercises are optional and are not graded by CodeGrade.  They can be used as extra optional practice.\n",
    "\n",
    "- What is the median year for the sets data?  Given the oldest and newest year in the data, what does this median value tell you about whether the number of sets have increased or decreased over the years?\n",
    "- What minifig has the most number of parts?\n",
    "- What minifig shows up in the most number of sets?\n",
    "- When was the first minifig included in a set?\n",
    "- What set has the most number of minifigs\n",
    "- What part is used the most for all sets? \n",
    "- What color is used the most for all parts?\n",
    "- Get a list of all unique color names, sort by color name, and output as a list. \n",
    "- How many total transparent colors are in the colors DataFrame?\n",
    "- Create a function called get_part_colors that takes as input a part number (as a string) and returns a DataFrame of all colors a part has appeared in.\n",
    "- What part / color combination is used the most for all sets?\n",
    "- What part / color combination is used the least for all sets?\n",
    "- Explore some of your favorite themes and which colors are used the most for those themes.\n",
    "- Plot a line graph of the average number of parts per set per year.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
